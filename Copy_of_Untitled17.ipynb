{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShotgunkeeperVZ/detectron2/blob/main/Copy_of_Untitled17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8G_t09g-P9a"
      },
      "outputs": [],
      "source": [
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "!pip install -U albumentations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8Quk0rI6SwEQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "DATASET = \"/content/gdrive/MyDrive/Dataset/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJ4qknubFAbf"
      },
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import random\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "def visualize(image,bbox=None):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.axis('off')\n",
        "    \n",
        "    if(bbox != None):\n",
        "        for box in bbox:\n",
        "            x = int(box[0])\n",
        "            y = int(box[1])\n",
        "            w = int(box[2])\n",
        "            h = int(box[3])\n",
        "            \n",
        "            # print(x,y,w,h)\n",
        "            cv2.rectangle(image,(x,y),(x+w,y+h),color=(255,0,0),thickness=6)\n",
        "            \n",
        "\n",
        "        \n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "ANNOTATIONS_CSV_PATH = DATASET + \"Annotations.csv\"\n",
        "AUGMENTED_CSV_PATH = DATASET + \"augment_labels.csv\"\n",
        "RAW_DATA = DATASET + \"Data/Train/\"\n",
        "AUGMENT_DIR = DATASET + \"Data_Augmented/\"\n",
        "\n",
        "# Probabilities\n",
        "\n",
        "\n",
        "annotations_df = pd.read_csv(ANNOTATIONS_CSV_PATH)\n",
        "\n",
        "if(os.path.isfile(AUGMENTED_CSV_PATH) == False):\n",
        "  os.system(\"rm -rf {}*\".format(AUGMENT_DIR))\n",
        "  transform = A.Compose([\n",
        "      A.LongestMaxSize(p=0.9999,max_size=800),\n",
        "      A.OneOf(transforms=(\n",
        "          A.HorizontalFlip(p=0.5),\n",
        "          A.VerticalFlip(p=0.5)\n",
        "   ),p=1.0,always_apply=True),\n",
        "\n",
        "\n",
        "      A.Affine(translate_percent={\"x\":(0,0.5),\"y\":(0.2,0.75)},p=0.5),\n",
        "      A.ChannelShuffle(p=0.25),\n",
        "      A.Posterize (num_bits=4, always_apply=False, p=0.3),\n",
        "      A.ColorJitter (brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, always_apply=False, p=0.6),\n",
        "      A.GaussNoise (var_limit=(10.0, 50.0), mean=0, per_channel=True, always_apply=False, p=0.35),\n",
        "\n",
        "      A.BBoxSafeRandomCrop(p=0.6),\n",
        "      A.OneOf(transforms=(A.Affine(scale=(1.15, 0.9)),\n",
        "              A.Affine(scale=(0.92, 1.05))), p=0.7),\n",
        "      A.RandomCropFromBorders(crop_left=0.15, crop_right=0.15, crop_top=0.15, crop_bottom=0.15, always_apply=False, p=0.35),\n",
        "      A.OneOf(transforms=(\n",
        "          A.Affine(shear=(2,0),p=1,scale=0.9),\n",
        "          A.Affine(shear=(0,3),p=1,scale=0.9)\n",
        "      ),p=0.67),\n",
        "      A.RandomResizedCrop (2000, 1000, scale=(0.7, 1.1), ratio=(0.8, 1.2), interpolation=1, always_apply=False, p=0.65),\n",
        "      A.RandomBrightness(limit=(-0.1, 0.1),p=1\n",
        "                        ),\n",
        "      A.RandomRotate90(p=0.45),\n",
        "      A.Rotate(limit=360, interpolation=1, border_mode=2, value=None, mask_value=None,\n",
        "              rotate_method='largest_box', crop_border=True, always_apply=False, p=0.2),\n",
        "      A.Flip(p=0.3),\n",
        "      A.RandomScale(p=0.8),\n",
        "      \n",
        "  ], bbox_params=A.BboxParams(format='coco', min_visibility=0.1))\n",
        "\n",
        "\n",
        "  for image in os.listdir(RAW_DATA):\n",
        "      relative_path = os.path.join(RAW_DATA, image)\n",
        "      if os.path.isfile(relative_path):\n",
        "          image_name = image\n",
        "          absolute_path = os.path.abspath(relative_path)\n",
        "\n",
        "          height = annotations_df[annotations_df.image_name == image].head(1).image_height\n",
        "          width = annotations_df[annotations_df.image_name == image].head(1).image_width\n",
        "\n",
        "          annotations = pd.DataFrame()\n",
        "\n",
        "          image_annotations = annotations_df[annotations_df.image_name == image]\n",
        "          image_annotations[\"label\"] = \"SPEC\"\n",
        "          image = cv2.imread(absolute_path)\n",
        "          # cv2.imwrite(AUGMENT_DIR+image_name,image)\n",
        "          # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "          bboxes = (image_annotations[[\n",
        "                    \"bbox_x\", \"bbox_y\", \"bbox_width\", \"bbox_height\", \"label\"]].to_numpy().tolist())\n",
        "          \n",
        "          for i in range(3 * int(np.random.normal(loc=3,scale=2))):\n",
        "              transformed = transform(image=image, bboxes=bboxes)\n",
        "              if(transformed[\"bboxes\"] == []):\n",
        "                continue\n",
        "              # visualize(transformed[\"image\"],transformed[\"bboxes\"])\n",
        "              \n",
        "              image_name_local = image_name.split(\".\")[0]+\"_A\"+str(i)+\".jpg\"\n",
        "              for box in transformed[\"bboxes\"]:\n",
        "                  x = int(box[0])\n",
        "                  y = int(box[1])\n",
        "                  w = int(box[2])\n",
        "                  h = int(box[3])\n",
        "                  new_box = pd.Series({\"label_name\":\"Spec\",\"bbox_x\":x,\"bbox_y\":y,\"bbox_width\":w,\"bbox_height\":h,\n",
        "                                      \"image_name\":image_name_local,\"image_width\":transformed[\"image\"].shape[1],\"image_height\":transformed[\"image\"].shape[0]})\n",
        "                  annotations_df = pd.concat([annotations_df,new_box.to_frame().T],ignore_index=True)\n",
        "              transformed_image = cv2.cvtColor(transformed[\"image\"], cv2.COLOR_BGR2RGB)\n",
        "              cv2.imwrite(AUGMENT_DIR + image_name_local,transformed_image)\n",
        "              image_name_local = \"\"\n",
        "  annotations_df.to_csv(index=False,path_or_buf=DATASET+\"augment_labels.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9lFxrYkOYp5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import torch\n",
        "import os\n",
        "from detectron2.data import DatasetCatalog\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "\n",
        "ANNOTATIONS_CSV_PATH = DATASET+\"augment_labels.csv\"\n",
        "TRAIN_DATA_DIR = DATASET+\"Data_Augmented/\"\n",
        "TEST_DATA_DIR = DATASET+\"Data/Test/\"\n",
        "\n",
        "annotations_df = pd.read_csv(ANNOTATIONS_CSV_PATH)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def register_dataset(directory):\n",
        "    dataset = []\n",
        "    for image in os.listdir(directory):\n",
        "\n",
        "        relative_path = os.path.join(directory, image)\n",
        "        if os.path.isfile(relative_path):\n",
        "            absolute_path = os.path.abspath(relative_path)\n",
        "            height = annotations_df[annotations_df.image_name == image][\"image_height\"].tolist()[0]\n",
        "            width = annotations_df[annotations_df.image_name == image][\"image_width\"].tolist()[0]\n",
        "            # display(height,width)\n",
        "            print(image,height,width)\n",
        "            annotations = pd.DataFrame()\n",
        "            image_annotations = annotations_df[annotations_df.image_name == image]\n",
        "           \n",
        "\n",
        "            annotations[\"bbox\"] = image_annotations[[\"bbox_x\", \"bbox_y\",\"bbox_width\", \"bbox_height\"]].to_numpy().tolist()\n",
        "            annotations[\"bbox\"] = annotations[\"bbox\"].apply(\n",
        "                lambda list: [float(i) for i in list])\n",
        "\n",
        "            annotations[\"bbox_mode\"] = BoxMode.XYWH_ABS\n",
        "            annotations[\"category_id\"] = 0\n",
        "            \n",
        "            annotations = list(annotations.to_dict('index').values())\n",
        "            \n",
        "            dataset.append({\n",
        "                \"file_name\":absolute_path,\n",
        "                \"height\":height,\n",
        "                \"width\" : width,\n",
        "                \"image_id\":image + \"_id\",\n",
        "                \"annotations\":annotations\n",
        "            })\n",
        "            # print(dataset)\n",
        "    return dataset   \n",
        "register_dataset(TRAIN_DATA_DIR)\n",
        "\n",
        "DatasetCatalog.register(\"Spec_Train\", lambda d=None: register_dataset(TRAIN_DATA_DIR))\n",
        "MetadataCatalog.get(\"Spec_Train\").set(thing_classes=[\"spec\"])\n",
        "# DatasetCatalog.register(\"Spec_Test\", lambda d=None: register_dataset(TEST_DATA_DIR))\n",
        "# MetadataCatalog.get(\"Spec_Test\").set(thing_classes=[\"spec\"])\n",
        "\n",
        "\n",
        "spec_dataset = MetadataCatalog.get(\"Spec_Train\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "L5Auc9k9WDMs"
      },
      "outputs": [],
      "source": [
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "\n",
        "cfg = get_cfg()\n",
        "os.makedirs(DATASET + \"OUTPUT\", exist_ok=True)\n",
        "\n",
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")\n",
        "cfg.DATASETS.TRAIN = (\"Spec_Train\",)\n",
        "# cfg.DATASETS.TEST = (\"Spec_Test\",)\n",
        "\n",
        "cfg.DATALOADER.NUM_WORKERS = 8\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4  # This is the real \"batch size\" commonly known to deep learning people\n",
        "cfg.SOLVER.BASE_LR = 0.0003  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 3000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
        "\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
        "cfg.OUTPUT_DIR = DATASET + \"OUTPUT\"\n",
        "\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=True)\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lhceeiYfhzSd"
      },
      "outputs": [],
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sB7F6_Wafstm"
      },
      "outputs": [],
      "source": [
        "# Inference should use the config with parameters that are used in training\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0ThNepeWf6dI"
      },
      "outputs": [],
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from google.colab.patches import cv2_imshow\n",
        "for image in os.listdir(TEST_DATA_DIR):\n",
        "  im = cv2.imread(TEST_DATA_DIR + image)\n",
        "  outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
        "  v = Visualizer(im[:, :, ::-1],metadata=spec_dataset,scale=0.5)\n",
        "  out = v.draw_instance_predictions(outputs[\"instances\"])\n",
        "  cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7FnFX1jX8SYS9VOjs3mYw",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}